{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: TensorFlow and Edge Detection using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from __future__ import division\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from utils import *\n",
    "from HOG import *\n",
    "from svm_estimator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eval_neg', 'train_neg', 'test_pos', 'eval_pos', 'train_pos', 'test_neg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data and start an InteractiveSession\n",
    "sess = tf.InteractiveSession()\n",
    "datasets = np.load('pedestrian_dataset.npz')    # extracted from the original Dalal and Triggs paper dataset available here: http://pascal.inrialpes.fr/data/human/\n",
    "[k for k in datasets.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 128, 64, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train_neg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128, 64, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([datasets['train_neg'], datasets['train_pos']], axis = 0).shape    # should be of size [#datapoints, 1152] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed29068c8b4d4be1ba8216685b9af905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0yNDksIGRlc2NyaXB0aW9uPXUnaycsIG1heD00OTkpLCBJbnRTbGlkZXIodmFsdWU9MCwgZGVzY3JpcHRpb249dSdwJywgbWHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### EXPLORE THE DATASET!\n",
    "# p=0 are negative examples\n",
    "# p=1 are positive examples\n",
    "@interact(k = (0, datasets[\"train_neg\"].shape[0] - 1), p = (0, 1))\n",
    "def view_img(k, p):\n",
    "    d = {0: \"train_neg\", 1: \"train_pos\"}\n",
    "    plt.imshow(datasets[d[p]][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80603e0d2a4146a08c5628ba830a81ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0yNDksIGRlc2NyaXB0aW9uPXUnaycsIG1heD00OTkpLCBJbnRTbGlkZXIodmFsdWU9MCwgZGVzY3JpcHRpb249dSdwJywgbWHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### VISUALIZE HOGs!\n",
    "# p=0 are negative examples\n",
    "# p=1 are positive examples\n",
    "@interact(k = (0, datasets[\"train_neg\"].shape[0]-1), p = (0, 1))\n",
    "def view_img(k, p):\n",
    "    d = {0: \"train_neg\", 1: \"train_pos\"}\n",
    "    plt.figure(figsize = (15,15))    # feel free to change this depending on your screen resolution\n",
    "    plt.imshow(datasets[d[p]][k])\n",
    "    # we can call .eval() instead of sess.run() below since we're using an InteractiveSession\n",
    "    plot_cell_hogs(tf_histogram_of_oriented_gradients(datasets[d[p]][k])[0].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do this after you have trained your SVM with HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NpzFile' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5a348261edd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmodel_number\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADD MODEL NUMBER IN training_checkpoints/hog/model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hog_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aa274/catkin_ws/src/AA274_hw2/Problem_3/svm_estimator.py\u001b[0m in \u001b[0;36mget_hog_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# These should be all be numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhog_descriptor\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpedestrian_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpedestrian_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# should be of size [#datapoints, 1152]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;31m# we also know that the first 500 examples were -1 and second 500 were +1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mx_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhog_descriptor\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpedestrian_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpedestrian_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# should be of size [#datapoints, 1152]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhog_descriptor\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpedestrian_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true_neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpedestrian_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aa274/catkin_ws/src/AA274_hw2/Problem_3/HOG.pyc\u001b[0m in \u001b[0;36mhog_descriptor\u001b[0;34m(img_raw, x_kernel, y_kernel, pixels_in_cell, cells_in_block, n_angle_bins)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhog_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_in_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcells_in_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_angle_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_histogram_of_oriented_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_in_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcells_in_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_angle_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_cell_hogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_hogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_in_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_angle_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"yellow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aa274/catkin_ws/src/AA274_hw2/Problem_3/HOG.pyc\u001b[0m in \u001b[0;36mtf_histogram_of_oriented_gradients\u001b[0;34m(img_raw, x_kernel, y_kernel, pixels_in_cell, cells_in_block, n_angle_bins)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtf_histogram_of_oriented_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_in_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcells_in_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_angle_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m## COMPUTE GRADIENT MAGNITUDES/ORIENTATIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_raw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m                           \u001b[0;31m# convert single image to batch of 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m)\u001b[0m                                                                             \u001b[0;31m# convert int pixel values to float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m                                                             \u001b[0;31m# x kernel is a row matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NpzFile' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "### VISUALIZE WEIGHTED HOGs!\n",
    "##################################\n",
    "# ADD MODEL NUMBER IN training_checkpoints/hog/model\n",
    "model_number = 1\n",
    "##################################\n",
    "assert model_number is not None, \"ADD MODEL NUMBER IN training_checkpoints/hog/model\"\n",
    "\n",
    "(x_train, y_train), (x_eval, y_eval), (x_pred, y_true) = get_hog_data()\n",
    "data = {}\n",
    "data['x_train'] = x_train\n",
    "data['y_train'] = y_train\n",
    "data['x_eval'] = x_eval\n",
    "data['y_eval'] = y_eval\n",
    "data['x_pred'] = x_pred\n",
    "data['y_true']  = y_true\n",
    "data['name'] = 'hog'\n",
    "estimator_model = svm(data, load=True)\n",
    "model_dir = \"training_checkpoints/hog/model/\" + str(model_number)\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    sess = tf.Session()\n",
    "    print(\"Loading model from: \" + model_dir)\n",
    "    tf.saved_model.loader.load(sess,\n",
    "                               [tf.saved_model.tag_constants.SERVING],\n",
    "                               model_dir)\n",
    "\n",
    "data = np.concatenate([datasets[\"test_pos\"], datasets[\"test_neg\"]], axis=0)\n",
    "\n",
    "weights = np.reshape(estimator_model.get_variable_value('svm/weights'), [1, -1])\n",
    "pos_weights = np.maximum(weights, 0)\n",
    "neg_weights = -np.minimum(weights, 0)\n",
    "file_exists = False\n",
    "try:\n",
    "    misclass_idx = np.load(\"hog_misclass_idx.npy\")\n",
    "    file_exists = True\n",
    "except OSError:\n",
    "    print(\"\\n\\nYou need to run the svm with HOG features first! hog_misclass_idx.py doesn't exist yet.\\n\\n\")\n",
    "\n",
    "if file_exists:\n",
    "    @interact(k = (0, data.shape[0]-1), show_image = (False, True))\n",
    "    def view_img(k, show_image):\n",
    "\n",
    "        misclass_idx = np.load(\"hog_misclass_idx.npy\")\n",
    "        plt.figure(figsize = (15,15))    # feel free to change this depending on your screen resolution\n",
    "        plt.imshow(data[k])\n",
    "        hog = hog_descriptor(data[k]).eval()\n",
    "        unweighted_block_hogs = np.mean(hog.reshape([16, 8, 1, 9]), axis=2)\n",
    "        pos_weighted_block_hogs = np.mean(pos_weights.reshape([16, 8, 1, 9])*hog.reshape([16, 8, 1, 9]), axis=2)\n",
    "        neg_weighted_block_hogs = np.mean(neg_weights.reshape([16, 8, 1, 9])*hog.reshape([16, 8, 1, 9]), axis=2)\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        color = 'yellow' if show_image else 'white'\n",
    "        plt.imshow(show_image*data[k])\n",
    "        plot_cell_hogs(unweighted_block_hogs, pixels_in_cell=8, color=color)\n",
    "        if k in misclass_idx:\n",
    "            plt.title(\"Misclassified!\")\n",
    "        else:\n",
    "            plt.title(\"Classified correctly\")\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(show_image*data[k])\n",
    "        plot_cell_hogs(pos_weighted_block_hogs, pixels_in_cell=8, color=color)\n",
    "        plt.title(\"Positive Weights\")\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(show_image*data[k])\n",
    "        plot_cell_hogs(neg_weighted_block_hogs, pixels_in_cell=8, color=color)\n",
    "        plt.title(\"Negative Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
